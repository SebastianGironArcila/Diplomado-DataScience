{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np2IauMtdthP"
   },
   "source": [
    "# PCA con los datos de las compras de supermercados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kp8WDahdthS"
   },
   "source": [
    "Vamos a realizar operaciones de **clustering** (segmentación) de datos.\n",
    "La idea es encontrar una estructura dentro de un dataset donde originalmente no la había.\n",
    "No se tiene un objetivo de predicción (se trata **aprendizaje no supervisado**), sino de uno de entendimiento de los datos a través del particionamiento del dataset en grupos de instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoK5CHP0dthT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, silhouette_samples, silhouette_score, calinski_harabaz_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EW0vm6NvdthU"
   },
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Za0EAJ2bdthU"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('01-ComprasClientes.csv', na_values=\".\")\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwzuQCgedthV"
   },
   "source": [
    "## Limpieza del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSaaZhjSdthV"
   },
   "source": [
    "1. Las variables Channel y Region tienen tipo int64, cuando en realidad codifican categorías de canales y de regiones. Es necesario cambiar sus tipos.\n",
    "1. Tenemos en todas las variables de consumo valores anormalmente grandes que pueden considerarse excepciones en el mejor de los casos (anomalías o errores de captura en el peor de los casos). Hay que identificar los registros en cuestión y evaluar la posibilidad de descartarlos pues pueden influenciar negativamente muchos de los modelos que se pueden aprender a partir de los datos.\n",
    "1. Las escalas de las variables que denotan los montos consumidos de cada tipo de productos son muy disparejas. Es necesario normalizar los datos ya que de no hacerlo se otorgaría una importancia demasiado desmedida a variables como Fresh casi que ignorando variables como Delicatessen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKXOcajhdthX"
   },
   "source": [
    "Arreglamos primero los tipos de datos incorrectos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzdg3d40dthX"
   },
   "outputs": [],
   "source": [
    "data.Channel = data.Channel.astype(str)\n",
    "data.Region = data.Region.astype(str)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vVMvqzfdthY"
   },
   "source": [
    "Vemos que hay valores muy importantes en todas las variables. Si contamos los puntos individuales más elevados podemos identificar 6 o menos puntos que sobrepasan la mayoría de los demás.\n",
    "Puede que algunos de los puntos excepcionales en las diferentes variables correspondan a los mismos individuos. Vamos a identificar los top 6 de valores mas importantes en cada tipo de producto y no los vamos a considerar en los análisis siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bNAfH2gdthY"
   },
   "outputs": [],
   "source": [
    "temp = data.sort_values(['Fresh'], ascending=False)\n",
    "print(\"Excepciones de Fresh: \", np.sort(temp[0:6].index.to_numpy()))\n",
    "indicesAQuitar = temp[0:6].index.to_numpy()\n",
    "\n",
    "temp = data.sort_values(['Milk'], ascending=False)\n",
    "print(\"Excepciones de Milk: \", np.sort(temp[0:6].index.to_numpy()))\n",
    "indicesAQuitar = np.union1d(indicesAQuitar, temp[0:6].index.to_numpy())\n",
    "\n",
    "temp = data.sort_values(['Grocery'], ascending=False)\n",
    "print(\"Excepciones de Grocery: \", np.sort(temp[0:6].index.to_numpy()))\n",
    "indicesAQuitar = np.union1d(indicesAQuitar, temp[0:6].index.to_numpy())\n",
    "\n",
    "temp = data.sort_values(['Frozen'], ascending=False)\n",
    "print(\"Excepciones de Frozen: \", np.sort(temp[0:6].index.to_numpy()))\n",
    "indicesAQuitar = np.union1d(indicesAQuitar, temp[0:6].index.to_numpy())\n",
    "\n",
    "temp = data.sort_values(['Detergents_Paper'], ascending=False)\n",
    "print(\"Excepciones de Detergents_Paper: \", np.sort(temp[0:6].index.to_numpy()))\n",
    "indicesAQuitar = np.union1d(indicesAQuitar, temp[0:6].index.to_numpy())\n",
    "\n",
    "temp = data.sort_values(['Delicassen'], ascending=False)\n",
    "print(\"Excepciones de Delicassen: \", np.sort(temp[0:6].index.to_numpy()))\n",
    "indicesAQuitar = np.union1d(indicesAQuitar, temp[0:6].index.to_numpy())\n",
    "\n",
    "indicesAQuitar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXfWwIEAdthZ"
   },
   "source": [
    "Tenemos 22 registros identificados como excepciones. Vemos que algunos tienen valores excepcionales según diferentes tipos de consumo (23, 47, 61, 65, 85, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UppwiYbndthZ"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFqsPzdndthZ"
   },
   "outputs": [],
   "source": [
    "dataDepurado = data.loc[~data.index.isin(indicesAQuitar)]\n",
    "dataDepurado.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orbanp6-dthZ"
   },
   "source": [
    "Vamos ahora a normalizar los datos para que todas las variables tengan la misma importancia. Solo vamos a considerar los datos numéricos, por lo que no incluimos las variables Channel y Region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPBW5bF2dtha"
   },
   "outputs": [],
   "source": [
    "dataStd = pd.DataFrame(preprocessing.scale(dataDepurado.iloc[:,2:]))\n",
    "dataStd.columns=dataDepurado.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JzwmU8Ddtha"
   },
   "outputs": [],
   "source": [
    "dataStd.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBbcV4sTdtha"
   },
   "outputs": [],
   "source": [
    "dataStd.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klsPkBQ8dtha"
   },
   "source": [
    "#  Reducción de dimensionalidad con PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzquuaSndtha"
   },
   "source": [
    "Vamos a buscar una mejor representación de los datos que nos permita conservar la mayor cantidad de información a través de la transformación de las 6 variables originales en componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwJA1bIsdtha"
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(dataStd.iloc[:, 0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igUiwwhgdthb"
   },
   "source": [
    "Una vez ajustado el objeto PCA a un dataset, este permite acceder a diferentes aspectos resultantes de la transformación:\n",
    "- components_: los ejes de los componentes principales en función de las variables originales. Como teníamos 6 variables, vamos a tener 6 PCs, cada uno con las cargas (*loadings*) correspondientes a cada variable original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjU3k1midthb"
   },
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPkSO9Pmdthb"
   },
   "source": [
    "- explained_variance_: la varianza explicada por cada eje en las unidades originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPFcxoETdthb"
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZK5j5q9dthb"
   },
   "source": [
    "- explained_variance_ratio_: la proporción de la varianza explicada por cada eje, en porcentaje (la suma da 100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHRfL-uZdthb"
   },
   "outputs": [],
   "source": [
    "var_exp=pca.explained_variance_ratio_ # varianza explicada por cada PC\n",
    "cum_var_exp = np.cumsum(var_exp) # varianza acumulada por los primeros n PCs\n",
    "var_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95c0rHdydthb"
   },
   "source": [
    "El objeto PCA sirve además para pasar de la representación en las dimensiones originales a la de las dimensiones en el espacio de los componentes principales encontrados, a partir de su método transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDTrFVLHdthc"
   },
   "outputs": [],
   "source": [
    "dataPca = pca.transform(dataStd.iloc[:, 0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axIdUaCvdthc"
   },
   "source": [
    "Veamos gráficamente la cantidad de información correspondiente a cada componente principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRIzWd_vdthc"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.bar(range(len(var_exp)), var_exp, alpha=0.3333, align='center', label='Varianza explicada por cada PC', color = 'g')\n",
    "plt.step(range(len(cum_var_exp)), cum_var_exp, where='mid',label='Varianza explicada acumulada')\n",
    "plt.ylabel('Porcentaje de varianza explicada')\n",
    "plt.xlabel('Componentes principales')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nUcfqN2dthc"
   },
   "outputs": [],
   "source": [
    "np.sum(pca.explained_variance_ratio_[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR8C8VgQdthc"
   },
   "source": [
    "Encontramos que los primeros 3 componentes conservan el 81.6% de la información original, y los primeros 4 el 93.2%.\n",
    "Vamos a quedarnos solo con los 3 primeros PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQOQG2LOdthc"
   },
   "outputs": [],
   "source": [
    "dataPca = dataPca[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8kNLxB1dthc"
   },
   "outputs": [],
   "source": [
    "dataPca[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw5L7eG0dthc"
   },
   "source": [
    "Vamos a ver los puntos en el nuevo sistema de representación dado por los componentes principales.\n",
    "Creamos una función que permite plotear tanto los puntos de los datos como los loadings de las variables originales (tomada de https://stackoverflow.com/questions/39216897/plot-pca-loadings-and-loading-in-biplot-in-sklearn-like-rs-autoplot).\n",
    "Esto nos permitirá entender mejor la relación entre componentes principales y variables originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qu45aM5Odthc"
   },
   "outputs": [],
   "source": [
    "def biplot(data, loadings, index1, index2, labels=None):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    xs = data[:,index1]\n",
    "    ys = data[:,index2]\n",
    "    n=loadings.shape[0]\n",
    "    scalex = 1.0/(xs.max()- xs.min())\n",
    "    scaley = 1.0/(ys.max()- ys.min())\n",
    "    plt.scatter(xs*scalex,ys*scaley)\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, loadings[i,index1], loadings[i,index2],color='r',alpha=0.5)\n",
    "        if labels is None:\n",
    "            plt.text(loadings[i,index1]* 1.15, loadings[i,index2] * 1.15, \"Var\"+str(i+1), color='g', ha='center', va='center')\n",
    "        else:\n",
    "            plt.text(loadings[i,index1]* 1.15, loadings[i,index2] * 1.15, labels[i], color='g', ha='center', va='center')\n",
    "    plt.xlim(-1,1)\n",
    "    plt.ylim(-1,1)\n",
    "    plt.xlabel(\"PC{}\".format(index1))\n",
    "    plt.ylabel(\"PC{}\".format(index2))\n",
    "    plt.grid() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3dO0vcmdthd"
   },
   "source": [
    "Veamos como nos va con los primeros dos componentes principales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aUj8zvydthd"
   },
   "outputs": [],
   "source": [
    "biplot(dataPca, pca.components_, 0, 1, ['Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mCWUHWWdthd"
   },
   "outputs": [],
   "source": [
    "biplot(dataPca, pca.components_, 0, 2, ['Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erqBiV2Zdthd"
   },
   "outputs": [],
   "source": [
    "dataStd.columns[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1goDisHRdthd"
   },
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA7GUS-4dthd"
   },
   "source": [
    "Podemos decir que:\n",
    "- El componente PC1 representa positivamente las compras de leche en su sentido positivo, y negativamente las compras en Groceries y Frozen. Las otras variables no tienen mayor incidencia.\n",
    "- El componente PC2 representa sobretodo las compras de Detergentes/Papel y Fresh (positivamente)\n",
    "- El componente PC3 representa sobretodo las compras de Delicatessen y Fresh (positivamente), y Detergentes/Papel y Frozen (negativamente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0349eJcdthd"
   },
   "source": [
    "Ahora que ya entendemos el significado de los componentes principales, podemos proseguir a un clustering de los registros en el espacio reducido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yg3be0Hdthd"
   },
   "outputs": [],
   "source": [
    "dataPca = pd.DataFrame(dataPca)\n",
    "dataPca.columns=['PC1', 'PC2', 'PC3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIX1FZj7dthd"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0, n_init=10)\n",
    "kmeans.fit(dataPca)\n",
    "clusters = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-3JjOB1dthd"
   },
   "outputs": [],
   "source": [
    "dataPca['Cluster']= clusters\n",
    "counter=Counter(clusters)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHPKrcHGdthd"
   },
   "outputs": [],
   "source": [
    "var_num = ['Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opsZkbbvdthe"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,15))\n",
    "i=1\n",
    "for var in dataPca.columns[0:3]:\n",
    "    ax = fig.add_subplot(math.ceil(len(var_num)/2), 2, i)\n",
    "    sns.kdeplot(dataPca.loc[dataPca.Cluster==0][var], shade=True, color='r', ax=ax);\n",
    "    sns.kdeplot(dataPca.loc[dataPca.Cluster==1][var], shade=True, color='b', ax=ax);\n",
    "    sns.kdeplot(dataPca.loc[dataPca.Cluster==2][var], shade=True, color='g', ax=ax);\n",
    "    plt.title(var)\n",
    "    plt.legend(['Cluster 0', 'Cluster 1', 'Cluster 2'])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6YvS26Idthe"
   },
   "source": [
    "Vemos que con K=3, El PC1 sirve para separar bien los puntos del cluster rojo (0), el PC2 sirve para distinguir el cluster verde (2). El cluster azul (1) no se puede separar directamente de los demas a través de uno de los PCs, pero si al considerar los 3 PCs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaPhpNGXdthe"
   },
   "source": [
    "Veamoslos en scatterplots para entender mejor las diferencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGhCpV3cdthe"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "colorPalette = [\"r\", \"b\", \"g\"]\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "sns.scatterplot(x=\"PC1\", y=\"PC2\", hue=\"Cluster\", data=dataPca, ax=ax, palette=colorPalette, s=100, alpha=0.5)\n",
    "plt.title(\"PC1 vs. PC2\")\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "sns.scatterplot(x=\"PC1\", y=\"PC3\", hue=\"Cluster\", data=dataPca, ax=ax, palette=colorPalette, s=100, alpha=0.5)\n",
    "plt.title(\"PC1 vs. PC3\")\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "sns.scatterplot(x=\"PC2\", y=\"PC3\", hue=\"Cluster\", data=dataPca, ax=ax, palette=colorPalette, s=100, alpha=0.5)\n",
    "plt.title(\"PC2 vs. PC3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDZnj1uadthf"
   },
   "source": [
    "Vemos que con K=3, en el plot de los 2 primeros PCs podemos separar bien los 3 clusters.\n",
    "Recordemos que el PC1 representa positivamente las compras de leche en su sentido positivo, y negativamente las compras en Groceries y Frozen, y que el componente PC2 representa sobretodo las compras de Detergentes/Papel y Fresh (positivamente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0WkMMAYdthf"
   },
   "source": [
    "**Nota**: Realizar la determinación del número de cluster puede hacerse tanto en el espacio de representación original (ya estandarizado) como en el de los componentes principales (considerandolos todos). Los resultados serán los mismos, ya que tanto el método del codo como el de la silueta se basan en cálculos de distancias, que se conservan después de la transformación en componentes temporales, que no es más que una rotación de los ejes.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03-SUPERMERCADOS-PCA-PROF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
